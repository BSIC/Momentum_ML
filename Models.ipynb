{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold, cross_val_score, RepeatedKFold, RandomizedSearchCV, PredefinedSplit\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score, roc_auc_score, confusion_matrix, classification_report, make_scorer, balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_signals = pd.read_csv('data/indicators.csv', parse_dates=True, index_col='Date')\n",
    "poly_features = pd.read_csv('data/indicators_w_polyterms.csv', parse_dates=True, index_col='Date')\n",
    "labels = pd.read_csv('data/Y_Matrix.csv', parse_dates=True, index_col='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the period rolling window over which we train new models and how far back the training data goes\n",
    "\n",
    "window = 1\n",
    "lookback = 3\n",
    "\n",
    "# Creating a function to generate the training and testing data for the models, from 2000 onwards we create for every single year a train test split\n",
    "# by using last 3 years as training data and the next year as testing data\n",
    "# Eg. the model that will trade between 2000 and 2001 will be trained on data from 1997 to 1999 and tuned on 1999 to 2000 data (for the purposes of hyperparameter tuning)\n",
    "\n",
    "def generate_data(reg_signals, labels, window, lookback):\n",
    "    '''\n",
    "    Function to generate training and testing data for the models\n",
    "    \n",
    "    Parameters:\n",
    "    reg_signals: DataFrame containing the  signals\n",
    "    labels: DataFrame containing the labels\n",
    "    window: int, number of years to use for the testing data\n",
    "    lookback: int, number of years to use for the training data\n",
    "    \n",
    "    '''\n",
    "    X = reg_signals\n",
    "    y = labels\n",
    "    X_train = []\n",
    "    X_test = []\n",
    "    y_train = []\n",
    "    y_test = []\n",
    "    for i in range(2000, 2025):\n",
    "        date = datetime.strptime(str(i) + '-01-01', '%Y-%m-%d')\n",
    "        X_train.append(X.loc[str(date - pd.DateOffset(years=lookback)):str(date - pd.DateOffset(years=window))])\n",
    "        X_test.append(X.loc[str(date - pd.DateOffset(years=window)):str(date)])\n",
    "        y_train.append(y.loc[str(date - pd.DateOffset(years=lookback)):str(date - pd.DateOffset(years=window))])\n",
    "        y_test.append(y.loc[str(date - pd.DateOffset(years=window)):str(date)])\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = generate_data(reg_signals, labels, window, lookback)\n",
    "X_poly_train, X_poly_test, y_poly_train, y_poly_test = generate_data(poly_features, labels, window, lookback)\n",
    "\n",
    "# NB: y_train and y_poly_train are the same for all models, as the y_backtest and y_poly_backtest are the same for all models, so we just keep one set\n",
    "del y_poly_train, y_poly_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tuning function for one single pipeline for one single period. We use the same training and testing data for all models to ensure that the results are comparable.\n",
    "# We use the predefined X_train, X_test split instead of cross-validation to avoid look-ahead biases.\n",
    "\n",
    "def tune_model(X_train, X_test, y_train, y_test, params, pipeline, hyperparameter_tuner='grid', n_iter=None, verbose=1, sample_weights=None, probability=True):\n",
    "    '''\n",
    "    Function to tune a model using a predefined split\n",
    "    \n",
    "    Parameters:\n",
    "    X_train: DataFrame, training data\n",
    "    X_test: DataFrame, testing data over which we perform the hyperparameter tuning\n",
    "    y_train: DataFrame, training labels\n",
    "    y_test: DataFrame, testing labels\n",
    "    params: dict, hyperparameters to tune\n",
    "    pipeline: Pipeline, model to tune\n",
    "    hyperparameter_tuner: str, 'grid' or 'random', default='grid'\n",
    "    n_iter: int, number of iterations for random search, default=None\n",
    "    verbose: int, default=1\n",
    "    sample_weights: array-like, default=None\n",
    "    probability: bool, whether the model has a predict_proba method, default=True\n",
    "    \n",
    "    '''\n",
    "    # we first merge the training and testing data\n",
    "    X = pd.concat([X_train, X_test])\n",
    "    y = pd.concat([y_train, y_test])\n",
    "    # our crossvalidation cv uses predefined split to ensure that the training and testing data are actually maintained when tuning hyperparameters:\n",
    "    cv = PredefinedSplit(test_fold=[-1]*len(X_train) + [0]*len(X_test))\n",
    "     \n",
    "    if probability:\n",
    "        scoring = {'auc': make_scorer(roc_auc_score, needs_proba=True, multi_class=\"ovr\"), 'f1_macro': 'f1_macro', 'precision': 'precision_macro', 'recall': 'recall_macro', 'balanced_accuracy': 'balanced_accuracy'}\n",
    "    else: \n",
    "        scoring = {'f1_macro': 'f1_macro', 'precision': 'precision_macro', 'recall': 'recall_macro', 'balanced_accuracy': 'balanced_accuracy'}\n",
    "    principal_metric = 'balanced_accuracy'\n",
    "\n",
    "    if hyperparameter_tuner == 'grid':\n",
    "        search = GridSearchCV(pipeline, params, cv=cv, scoring=scoring, refit=principal_metric, n_jobs=-1, verbose=verbose, error_score='raise')\n",
    "    elif hyperparameter_tuner == 'random':\n",
    "        search = RandomizedSearchCV(pipeline, params, cv=cv, scoring=scoring, refit=principal_metric, n_iter=n_iter, n_jobs=-1, verbose=verbose)\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown hyperparameter tuner: {hyperparameter_tuner}\\n Choose from 'grid', 'random'\")\n",
    "    if sample_weights is not None:\n",
    "        kwargs = {pipeline.steps[-1][0] + '__sample_weight': sample_weights}\n",
    "        result = search.fit(X, y, **kwargs)\n",
    "    else:\n",
    "        result = search.fit(X, y)\n",
    "    best_model = result.best_estimator_\n",
    "\n",
    "    return result, best_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defining the Pipelines for each Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "log_reg_pipeline = Pipeline(\n",
    "    [('log_reg', LogisticRegression(max_iter=1000))]\n",
    ")\n",
    "\n",
    "# Define the parameters to tune\n",
    "log_reg_params = {\n",
    "    'log_reg__C': [0.01, 0.1, 1, 10, 100],\n",
    "    'log_reg__penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'log_reg__class_weight': ['balanced', None]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "rf_pipeline = Pipeline(\n",
    "    [('rf', RandomForestClassifier())]\n",
    ")\n",
    "\n",
    "# Define the parameters to tune\n",
    "rf_params = {\n",
    "    'rf__n_estimators': [100, 200, 300, 400, 500],\n",
    "    'rf__max_depth': [10, 20, 30, 40, 50],\n",
    "    'rf__min_samples_split': [2, 5, 10],\n",
    "    'rf__min_samples_leaf': [1, 2, 4],\n",
    "    'rf__bootstrap': [True, False],\n",
    "    'rf__class_weight': ['balanced', None]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "xgb_pipeline = Pipeline(\n",
    "    [('xgb', XGBClassifier())]\n",
    ")\n",
    "\n",
    "# Define the parameters to tune\n",
    "xgb_params = {\n",
    "    'xgb__n_estimators': [100, 200, 300, 400, 500],\n",
    "    'xgb__max_depth': [3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    'xgb__learning_rate': [0.01, 0.1, 0.2, 0.3],\n",
    "    'xgb__subsample': [0.5, 0.7, 0.9, 1],\n",
    "    'xgb__colsample_bytree': [0.5, 0.7, 0.9, 1],\n",
    "    'xgb__gamma': [0, 0.1, 0.2, 0.3, 0.4, 0.5],\n",
    "    'xgb__reg_alpha': [0, 0.1, 0.5, 1],\n",
    "    'xgb__reg_lambda': [0, 0.1, 0.5, 1],\n",
    "    'xgb__scale_pos_weight': [1, 2, 3, 4, 5],\n",
    "    'xgb__eval_metric': ['mlogloss', 'merror'],\n",
    "    'xgb__objective': ['multi:softmax', 'multi:softprob']\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the pipeline\n",
    "svm_pipeline = Pipeline(\n",
    "    [('svm', SVC(probability=True))]\n",
    ")\n",
    "\n",
    "# Define the parameters to tune\n",
    "svm_params = {\n",
    "    'svm__C': [0.1, 1, 10, 100],\n",
    "    'svm__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "    'svm__degree': [2, 3, 4, 5],\n",
    "    'svm__gamma': ['scale', 'auto'],\n",
    "    'svm__class_weight': ['balanced', None]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
